{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error #to calculate metrics for the model later\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stonk = np.array([\"GOOG\", \"IBM\", \"MMM\", \"AMZN\", \"AAPL\", \"TSLA\", \"NIO\", \"NIU\", \"FSLR\", \"FB\", \"QRVO\"])\n",
    "stonk = widgets.SelectMultiple(\n",
    "    options = unique_stonk.tolist(),\n",
    "    value = ['GOOG'],\n",
    "    description='Stonk',\n",
    "    disabled=False,\n",
    "    layout = Layout(width='50%', height='80px', display='flex')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi_cal(dta3):\n",
    "    dta3['change_in_price'] = dta3['Close'].diff() #create the change in price column which calculates gains/losses\n",
    "\n",
    "    #now we need to create an \"up\" and a \"down\" column, containing gains/losses, to calculate the Relative Strength\n",
    "    up = dta3[['change_in_price']].copy()\n",
    "    down = dta3[['change_in_price']].copy()\n",
    "\n",
    "    #up only contains gains, losses are marked as 0. down only contains losses, gains are marked as 0\n",
    "    for i in range(len(up['change_in_price'])):\n",
    "        if up['change_in_price'][i] < 0: \n",
    "            up['change_in_price'][i] = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    for i in range(len(down['change_in_price'])):\n",
    "        if down['change_in_price'][i] >0: \n",
    "            down['change_in_price'][i] = 0\n",
    "        else:\n",
    "            down['change_in_price'][i] = abs(down['change_in_price'][i]) #we want all changes to be in absolute value\n",
    "\n",
    "\n",
    "    #Avoid data leakage\n",
    "    df_up = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_up = df_up.append(up['change_in_price'], ignore_index=True)\n",
    "    df_up.drop(df_up.tail(1).index,inplace=True)\n",
    "    up['change_in_price'] = df_up\n",
    "    df_down = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_down = df_down.append(down['change_in_price'], ignore_index=True)\n",
    "    df_down.drop(df_down.tail(1).index,inplace=True)\n",
    "    down['change_in_price'] = df_down\n",
    "\n",
    "\n",
    "    # Calculate the EWMA (Exponential Weighted Moving Average)\n",
    "    ewma_up = up['change_in_price'].transform(lambda x: x.ewm(span = 14).mean())\n",
    "    ewma_down = down['change_in_price'].transform(lambda x: x.ewm(span = 14).mean())\n",
    "\n",
    "    # Calculate the RS\n",
    "    RS = ewma_up/ewma_down\n",
    "\n",
    "    # Calculate the RSI\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "\n",
    "    dta3['down_days'] = down['change_in_price']\n",
    "    dta3['up_days'] = up['change_in_price']\n",
    "    dta3['RSI'] = RSI\n",
    "    #We will drop the Nas latter\n",
    "    return dta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoc_oscillator_cal(dta3):\n",
    "    #Creating the high and low columns\n",
    "    high14 = dta3[['High']].copy()\n",
    "    low14 = dta3[['Low']].copy()\n",
    "    close_pushed = dta3['Close'].copy()\n",
    "    df_high = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_high = df_high.append(high14, ignore_index=True)\n",
    "    df_high.drop(df_high.tail(1).index,inplace=True)\n",
    "    high14 = df_high\n",
    "    df_low = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_low = df_low.append(low14, ignore_index=True)\n",
    "    df_low.drop(df_low.tail(1).index,inplace=True)\n",
    "    low14 = df_low\n",
    "    df_close = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_close = df_close.append(close_pushed, ignore_index=True)\n",
    "    df_close.drop(df_close.tail(1).index,inplace=True)\n",
    "    close_pushed = df_close\n",
    "\n",
    "\n",
    "    # We use the roll function to calculate the H14 and L14\n",
    "    high14 = high14['High'].transform(lambda x: x.rolling(window = 14).min())\n",
    "    low14 = low14['Low'].transform(lambda x: x.rolling(window = 14).max())\n",
    "\n",
    "    # Calculation of Stochastic Oscillator.\n",
    "    stoc_oscillator = 100 * ((close_pushed - low14) / (high14 - low14))\n",
    "    dta3['low14'] = low14\n",
    "    dta3['high14'] = high14\n",
    "    dta3['k_percent'] = stoc_oscillator\n",
    "    return dta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prc_cal(dta3):\n",
    "    #the pct_change function helps us calculate the percentage change compared to n periods before\n",
    "    close_pushed = dta3['Close'].copy()\n",
    "    df_close = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_close = df_close.append(close_pushed, ignore_index=True)\n",
    "    df_close.drop(df_close.tail(1).index,inplace=True)\n",
    "    close_pushed = df_close\n",
    "    dta3['PRC'] = close_pushed.transform(lambda x: x.pct_change(periods = 50))\n",
    "    return dta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd_cal(dta3):\n",
    "    #Again, push to avoid data leakage\n",
    "    close_pushed = dta3['Close'].copy()\n",
    "    df_close = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_close = df_close.append(close_pushed, ignore_index=True)\n",
    "    df_close.drop(df_close.tail(1).index,inplace=True)\n",
    "    close_pushed = df_close\n",
    "\n",
    "    #Again, use the ewm function like above for calculating EMA of the last 26 and 12 days\n",
    "    ema26 = dta3['Close'].transform(lambda x: x.ewm(span = 26).mean())\n",
    "    ema12 = dta3['Close'].transform(lambda x: x.ewm(span = 12).mean())\n",
    "    macd = ema12 - ema26\n",
    "    #Signal line\n",
    "    ema_9_macd = macd.ewm(span = 9).mean()\n",
    "    dta3['MACD'] = macd\n",
    "    dta3['MACD_EMA'] = ema_9_macd\n",
    "    return dta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_william_cal(dta3):\n",
    "    #Calculation process is very similar to the Stochastic Oscillator. Again, we push to avoid data leakage\n",
    "    high14 = dta3[['High']].copy()\n",
    "    low14 = dta3[['Low']].copy()\n",
    "    close_pushed = dta3['Close'].copy()\n",
    "    df_high = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_high = df_high.append(high14, ignore_index=True)\n",
    "    df_high.drop(df_high.tail(1).index,inplace=True)\n",
    "    high14 = df_high\n",
    "    df_low = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_low = df_low.append(low14, ignore_index=True)\n",
    "    df_low.drop(df_low.tail(1).index,inplace=True)\n",
    "    low14 = df_low\n",
    "    df_close = pd.Series([np.nan]) #add one more NaN value at the beginning\n",
    "    df_close = df_close.append(close_pushed, ignore_index=True)\n",
    "    df_close.drop(df_close.tail(1).index,inplace=True)\n",
    "    close_pushed = df_close\n",
    "\n",
    "    # We use the roll function to calculate the H14 and L14\n",
    "    high14 = high14['High'].transform(lambda x: x.rolling(window = 14).min())\n",
    "    low14 = low14['Low'].transform(lambda x: x.rolling(window = 14).max())\n",
    "\n",
    "    # Calculate William %R \n",
    "    r_william = ((high14 - close_pushed) / (high14 - low14)) * - 100\n",
    "    dta3['r_william'] = r_william\n",
    "    return dta3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(stonk):\n",
    "    results={}\n",
    "    for ticker in stonk:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        # get historical market data\n",
    "        dta = stock.history(period=\"759d\") #5 years - each year has 253 trading days\n",
    "        dta['Date']=dta.index\n",
    "        dta.reset_index(drop=True, inplace=True)\n",
    "        #Start adding the features\n",
    "        dta=rsi_cal(dta)\n",
    "        dta=stoc_oscillator_cal(dta)\n",
    "        dta=prc_cal(dta)\n",
    "        dta=macd_cal(dta)\n",
    "        dta=r_william_cal(dta)\n",
    "        dta=dta.dropna()\n",
    "        #Training the model\n",
    "        total = 759\n",
    "        valid = int(total*0.4) # 40% of the data like above as test data\n",
    "        train = dta.count()[0] - valid #60% of the data to train\n",
    "\n",
    "        #make a copy so we leave the dta3 data set unchanged\n",
    "        dta_copy = dta\n",
    "        #including different features from above\n",
    "        features = ['Open','Close', 'Low', 'High', 'Volume','RSI','k_percent', 'PRC', 'r_william', 'MACD']\n",
    "        x_dta = dta_copy[features]\n",
    "        y_dta = dta_copy['Close']\n",
    "        x_training = x_dta[:train]\n",
    "        x_val = x_dta[train:]\n",
    "        y_training = y_dta[:train]\n",
    "        y_val = y_dta[train:]\n",
    "        x_val.drop(['RSI','k_percent', 'PRC', 'r_william', 'MACD'], axis=1)\n",
    "        #this makes the test data to be completely independent of the training data - I removed all the technical features\n",
    "\n",
    "        model = RandomForestRegressor(bootstrap=True)\n",
    "        model.fit(x_training, y_training)\n",
    "        forecast_forest = model.predict(x_val)\n",
    "        real = y_dta[train:]\n",
    "\n",
    "        # report performance\n",
    "        mse = mean_squared_error(real, forecast_forest)\n",
    "        rmse = math.sqrt(mean_squared_error(real, forecast_forest))\n",
    "        mape = np.mean(np.abs(np.array(forecast_forest) - real)/np.abs(real))\n",
    "        forest_plot_data = y_training.tolist() + forecast_forest.tolist()\n",
    "        plt.plot(forest_plot_data)\n",
    "    results[ticker]=forecast_forest\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b997cea71b248f0a718a4a547057db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Stonk', index=(0,), layout=Layout(display='flex', height='80…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(randomforest, stonk=stonk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest_nographs(stonk):\n",
    "    results={}\n",
    "    for ticker in stonk:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        # get historical market data\n",
    "        dta = stock.history(period=\"759d\") #5 years - each year has 253 trading days\n",
    "        dta['Date']=dta.index\n",
    "        dta.reset_index(drop=True, inplace=True)\n",
    "        #Start adding the features\n",
    "        dta=rsi_cal(dta)\n",
    "        dta=stoc_oscillator_cal(dta)\n",
    "        dta=prc_cal(dta)\n",
    "        dta=macd_cal(dta)\n",
    "        dta=r_william_cal(dta)\n",
    "        dta=dta.dropna()\n",
    "        #Training the model\n",
    "        total = 759\n",
    "        valid = int(total*0.4) # 40% of the data like above as test data\n",
    "        train = dta.count()[0] - valid #60% of the data to train\n",
    "\n",
    "        #make a copy so we leave the dta3 data set unchanged\n",
    "        dta_copy = dta\n",
    "        #including different features from above\n",
    "        features = ['Open','Close', 'Low', 'High', 'Volume','RSI','k_percent', 'PRC', 'r_william', 'MACD']\n",
    "        x_dta = dta_copy[features]\n",
    "        y_dta = dta_copy['Close']\n",
    "        x_training = x_dta[:train]\n",
    "        x_val = x_dta[train:]\n",
    "        y_training = y_dta[:train]\n",
    "        y_val = y_dta[train:]\n",
    "        x_val.drop(['RSI','k_percent', 'PRC', 'r_william', 'MACD'], axis=1)\n",
    "        #this makes the test data to be completely independent of the training data - I removed all the technical features\n",
    "\n",
    "        model = RandomForestRegressor(bootstrap=True)\n",
    "        model.fit(x_training, y_training)\n",
    "        forecast_forest = model.predict(x_val)\n",
    "        real = y_dta[train:]\n",
    "\n",
    "        # report performance\n",
    "        mse = mean_squared_error(real, forecast_forest)\n",
    "        rmse = math.sqrt(mean_squared_error(real, forecast_forest))\n",
    "        mape = np.mean(np.abs(np.array(forecast_forest) - real)/np.abs(real))\n",
    "        results[ticker]=forecast_forest.tolist()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "np.random.seed(777)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annualise(allocation, mean_returns, covariance):\n",
    "    \"\"\"Function to annualise the standard deviation and return of each portfolio\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    allocation\n",
    "        The weight given to each stock in the portfolio\n",
    "    mean_returns\n",
    "        The mean return of each stock in the portfolio\n",
    "    covariance\n",
    "        The covariance matrix of the stocks in the portfolio\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    std_annual\n",
    "        annualised standard deviation\n",
    "    return_annual\n",
    "        annualised return\n",
    "\n",
    "    \"\"\"\n",
    "    std_annual = np.sqrt(np.dot(allocation.T, np.dot(covariance, allocation))) * np.sqrt(252)\n",
    "    return_annual = np.sum(mean_returns*allocation ) *252 #252 trading days per year\n",
    "    return std_annual, return_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_portfolios(df, mean_returns, covariance, risk_free_rate):\n",
    "    \"\"\"Function to create 50000 random portfolios using the above stocks for the efficient frontier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean_returns\n",
    "        The mean return of each stock in the portfolio\n",
    "    covariance\n",
    "        The covariance matrix of the stocks in the portfolio\n",
    "    risk_free_rate\n",
    "        Current risk-free rate. We want to invest the cash portion of the portfolio in risk-free treasury\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results\n",
    "        list of standard deviation, return and Sharpe ratio of each portfolio\n",
    "    list_weights\n",
    "        list of portfolios\n",
    "\n",
    "    \"\"\"\n",
    "    list_weights = []\n",
    "    results = np.zeros((3,1000)) #30000 portfolios\n",
    "    for i in range(1000):\n",
    "        allocation = np.random.random(len(df.columns)) #randoming the allocation \n",
    "        allocation = allocation/sum(allocation) #normalizing the randomed vectors so they sum to 1\n",
    "        list_weights.append(allocation)\n",
    "        std_dev = annualise(allocation, mean_returns, covariance)[0] #annualise the std and return of the portfolio\n",
    "        returns = annualise(allocation, mean_returns, covariance)[1]\n",
    "        results[0,i] = std_dev  \n",
    "        results[1,i] = returns \n",
    "        results[2,i] = (returns - risk_free_rate) / std_dev #Sharpe ratio\n",
    "    return results, list_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we define function to plot the efficient frontier with the optimal portfolio highlighted using the results above.\n",
    "The optimal portfolio is found by taking the portfolio with the maximum Sharpe ratio (excess returns given the risk)\n",
    "among the 50000 portfolios that we randomly created. We also display the portfolio with the smallest possible \n",
    "risk.\n",
    "'''\n",
    "\n",
    "def display_simulated_ef_with_random(stonk):\n",
    "    \"\"\"Function graph the efficient frontier and print out the optimal portfolios\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean_returns\n",
    "        The mean return of each stock in the portfolio\n",
    "    covariance\n",
    "        The covariance matrix of the stocks in the portfolio\n",
    "    risk_free_rate\n",
    "        Current risk-free rate. We want to invest the cash portion of the portfolio in risk-free treasury\n",
    "    \"\"\"\n",
    "    price_dict=randomforest_nographs(stonk)\n",
    "    df = pd.DataFrame(data=price_dict)\n",
    "    returns = df.pct_change()\n",
    "    mean_returns = returns.mean()\n",
    "    covariance = returns.cov()\n",
    "    risk_free_rate = 0.0083\n",
    "    \n",
    "    \n",
    "    results = create_random_portfolios(df, mean_returns, covariance, risk_free_rate)[0]\n",
    "    weights = create_random_portfolios(df, mean_returns, covariance, risk_free_rate)[1]\n",
    "    #For the portfolio with maximum sharpe\n",
    "    index_max_sharpe = np.argmax(results[2]) #the maximum sharpe ratio among 30000 portfolios randomed\n",
    "    std_max_sharpe = results[0,index_max_sharpe]\n",
    "    return_max_sharpe = results[1,index_max_sharpe]\n",
    "    allocation_max_sharpe = weights[index_max_sharpe]\n",
    "    #For the portfolio with the lowest risk\n",
    "    index_min_risk = np.argmin(results[0])\n",
    "    std_min_risk = results[0, index_min_risk]\n",
    "    return_min_risk = results[1, index_min_risk]\n",
    "    allocation_min_risk = weights[index_min_risk]\n",
    "    #Printing out the results    \n",
    "    print(\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", return_max_sharpe)\n",
    "    print(\"Annualised Volatility:\", std_max_sharpe)\n",
    "    print(df.columns.tolist())\n",
    "    print(allocation_max_sharpe)\n",
    "    print(\"Minimum Volatility Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", return_min_risk)\n",
    "    print(\"Annualised Volatility:\", std_min_risk)\n",
    "    print(df.columns.tolist())\n",
    "    print(allocation_min_risk)\n",
    "    #Visualizing with a scatterplot\n",
    "    plt.figure(figsize = (15,10))\n",
    "    std_applicable = []\n",
    "    return_applicable=[]\n",
    "    for i in range(len(results[0,:])): #only display the upper part of the frontier\n",
    "        if results[1,i] > return_min_risk:\n",
    "            std_applicable.append(results[0,i])\n",
    "            return_applicable.append(results[1,i])\n",
    "        else:\n",
    "            pass\n",
    "    plt.scatter(std_applicable,return_applicable, marker='o', s=10) #all portfolios\n",
    "    plt.scatter(std_max_sharpe,return_max_sharpe,marker='*',color='red',s=500, label='Maximum Sharpe ratio')\n",
    "    plt.scatter(std_min_risk,return_min_risk,marker='*',color='yellow',s=500, label='Minimum volatility')\n",
    "    plt.legend()\n",
    "    plt.title('Efficient frontier with optimized portfolios')\n",
    "    plt.xlabel('Risk')\n",
    "    plt.ylabel('Return')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48472fd1b84b4b3ebf774c31301fe8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Stonk', index=(0,), layout=Layout(display='flex', height='80…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(display_simulated_ef_with_random, stonk=stonk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
